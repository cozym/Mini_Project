{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **응급상황 자동 인식 및 응급실 연계 서비스**\n","# **단계4 : 통합-모듈화**"],"metadata":{"id":"4p06IPOk5xil"}},{"cell_type":"markdown","source":["## **0.미션**\n","\n","단계 4에서는, 단계1,2,3 에서 생성한 함수들을 모듈화하고, 단위 테스트 및 파이프라인 코드를 작성합니다."],"metadata":{"id":"HRuiqkZnuq94"}},{"cell_type":"markdown","source":["* **미션6**\n","    * Python 코드 모듈화\n","        * 각 모듈 코드 및 모델, 데이터파일을 일관성 있게 정리\n","        * .py 파일 생성 ==> 라이브러리 로딩, 각 task를 위한 함수 생성\n"],"metadata":{"id":"B-RC4OGVuq9-"}},{"cell_type":"markdown","source":["## **1.환경설정**"],"metadata":{"id":"76Pw6f64d5VU"}},{"cell_type":"markdown","source":["* 경로 설정\n","\n","구글 드라이브 연결"],"metadata":{"id":"1is0ZmzXeBrA"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"kOfI9W-Kc8eF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732158194808,"user_tz":-540,"elapsed":2288,"user":{"displayName":"배현수","userId":"11677928815105267127"}},"outputId":"63ee7a5b-45e5-4e73-b60e-f676b569a4a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/project6_2/'"],"metadata":{"id":"JhVujnYp4TJe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"_IpihoNGpt_I"}},{"cell_type":"markdown","source":["## 2.모듈 구성하기"],"metadata":{"id":"9U7SbaB7cSSx"}},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/project6/emergency.py\n","\n","import os\n","import requests\n","import xml.etree.ElementTree as ET\n","import pandas as pd\n","import openai\n","from openai import OpenAI\n","import json\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","# 0. load key file------------------\n","\n","#OpenAI API Key 환경 변수 설정\n","def load_key_file(filepath):\n","  with open(filepath, 'r') as file:\n","    return file.readline().strip()\n","\n","  # API 키 로드 및 환경변수 설정\n","path = '/content/drive/MyDrive/project6_2/'\n","openai.api_key = load_key_file(path + 'api_key.txt')\n","os.environ['OPENAI_API_KEY'] = openai.api_key\n","\n","\n","# 1-1 audio2text--------------------\n","def audio2text(audio_path, filename):\n","    # OpenAI 클라이언트 생성\n","    client = OpenAI()\n","\n","    file_path = os.path.join(audio_path, filename)\n","    try:\n","        with open(file_path, \"rb\") as audio_file:\n","            input_text = client.audio.transcriptions.create(\n","                file=audio_file,\n","                model=\"whisper-1\",\n","                language=\"ko\",\n","                response_format=\"text\",\n","            )\n","        return input_text\n","    except Exception as e:\n","        return f\"Error occurred: {str(e)}\"\n","\n","# 1-2 text2summary------------------\n","\n","def text2summary(input_text, filename, x, y):\n","      # OpenAI 클라이언트 생성\n","      client = OpenAI()\n","\n","      # 시스템 역할과 응답 형식 지정\n","      system_role = '''당신은 119 전화 내용을 요약하는 어시스턴트입니다.\n","      응답은 다음의 형식을 지켜주세요\n","      {\"summary\": \\\"텍스트 요약\\\"}\n","      '''\n","\n","\n","\n","      # 입력데이터를 GPT-3.5-turbo에 전달하고 답변 받아오기\n","      response = client.chat.completions.create(\n","          model=\"gpt-3.5-turbo\",\n","          messages=[\n","              {\n","                  \"role\": \"system\",\n","                  \"content\": system_role\n","              },\n","              {\n","                  \"role\": \"user\",\n","                  \"content\": input_text\n","              }\n","          ]\n","      )\n","\n","      # 응답 받기\n","      answer = response.choices[0].message.content\n","\n","      # 응답형식을 정리하고 return\n","      summary = eval(answer)[\"summary\"]\n","\n","      # 결과 데이터프레임 생성\n","      result = {\n","          \"Filename\": filename,\n","          \"Summary\": summary,\n","          \"위도\": x,\n","          \"경도\": y\n","        }\n","\n","      return result\n","\n","\n","# 2. model prediction------------------\n","\n","def predict(text, model, tokenizer):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # 입력 문장 토크나이징\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n","    inputs = {key: value.to(device) for key, value in inputs.items()}  # 각 텐서를 GPU로 이동\n","\n","    # 모델 예측\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    # 로짓을 소프트맥스로 변환하여 확률 계s산\n","    logits = outputs.logits\n","    probabilities = logits.softmax(dim=1)\n","\n","    # 가장 높은 확률을 가진 클래스 선택\n","    pred = torch.argmax(probabilities, dim=-1).item()\n","    predicted_grade = pred + 1\n","\n","    return predicted_grade\n","\n","\n","def add_grade(result ,path):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    save_directory = path + \"fine_tuned_bert\"\n","\n","    # 모델 로드\n","    loaded_model = AutoModelForSequenceClassification.from_pretrained(save_directory).to(device)\n","\n","    # 토크나이저 로드\n","    loaded_tokenizer = AutoTokenizer.from_pretrained(save_directory)\n","\n","    predicted_grade = predict(result['Summary'], loaded_model, loaded_tokenizer)\n","\n","    result[\"grade\"] = predicted_grade\n","\n","    return result\n","\n","\n","# 3-1. get_distance------------------\n","def get_dist(start_lat, start_lng, dest_lat, dest_lng, c_id, c_key):\n","    url = \"https://naveropenapi.apigw.ntruss.com/map-direction/v1/driving\"\n","    headers = {\n","        \"X-NCP-APIGW-API-KEY-ID\": c_id,\n","        \"X-NCP-APIGW-API-KEY\": c_key,\n","    }\n","    params = {\n","        \"start\": f\"{start_lng},{start_lat}\",  # 출발지 (경도, 위도)\n","        \"goal\": f\"{dest_lng},{dest_lat}\",    # 목적지 (경도, 위도)\n","        \"option\": \"trafast\"  # 실시간 빠른 길 옵션\n","    }\n","\n","    # 요청하고, 답변 받아오기\n","    response = requests.get(url, headers=headers, params=params)\n","    response = response.json()\n","    dist = response['route']['trafast'][0]['summary']['distance']  # m(미터)\n","    duration = response['route']['trafast'][0]['summary']['duration'] # 도착시간(ms)\n","    return dist, duration\n","\n","\n","def convert_milliseconds(df): # 변환 함수\n","    duration = df['duration'].copy()\n","    duration = duration.to_list()\n","    dur = []\n","    for ms in duration:\n","      ms %= 3600000\n","      minutes = ms // 60000\n","      ms %= 60000\n","      seconds = ms // 1000\n","      dur.append(f\" {minutes}분 {seconds}초\")\n","    return dur\n","\n","# 3-2. recommendation------------------\n","\n","def recommendation(em_list, x, y, c_id, c_key):\n","    dist = []\n","    duration = []\n","    distrange = 0.1\n","    neighbor = em_list.loc[\n","    (abs(em_list['위도'] - x) <= distrange) &\n","    (abs(em_list['경도'] - y) <= distrange)].copy()\n","\n","    if(len(neighbor)<=3):\n","      neighbor = em_list.loc[\n","      (abs(em_list['위도'] - x) <= distrange + 0.1) &\n","      (abs(em_list['경도'] - y) <= distrange + 0.1)].copy()\n","\n","    for lat, long in zip(neighbor['위도'], neighbor['경도']):\n","        di, du = get_dist(x, y, lat, long, c_id, c_key)\n","        dist.append(di)\n","        duration.append(du)\n","\n","    neighbor['dist'] = dist\n","    neighbor['duration'] = duration\n","    return neighbor.sort_values(by='dist').head(3), neighbor.sort_values(by='duration').head(3)\n","\n"],"metadata":{"id":"HAyk26O8bFQJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732158309766,"user_tz":-540,"elapsed":319,"user":{"displayName":"배현수","userId":"11677928815105267127"}},"outputId":"93acf87e-b15b-435a-f324-27cbf8bad2e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing /content/drive/MyDrive/project6/emergency.py\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"01-BNX5HWRse"},"execution_count":null,"outputs":[]}]}